{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34d8c920",
   "metadata": {},
   "source": [
    "# ISM6251.003S23- Assignment 1\n",
    "\n",
    "\n",
    "## Business Problem\n",
    "The aim is to create a predictive model using the patient characteristics provided, which can determine if a patient has heart disease or not. If the model proves effective, it could be utilized by the medical sector to anticipate heart disease in new patients who possess the necessary data. This will enable them to prioritize patients for diagnostic testing, surgeries, and other treatments.\n",
    "\n",
    "## Description of the analysis\n",
    "This project aims to determine the evaluation metrics employed for assessing the performance of the model(s) and explain the rationale behind the selection of these metrics. The logistic regression, SVM, and decision tree models will be utilized for modeling purposes. To test a variety of parameter values for each model, both random and grid searches will be performed for each of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16031437",
   "metadata": {},
   "source": [
    "### 1. Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8b7d370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d6e2f3",
   "metadata": {},
   "source": [
    "### 2. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4935f8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"heart_train_X.csv\")\n",
    "X_test = pd.read_csv(\"heart_test_X.csv\")\n",
    "y_train = pd.read_csv(\"heart_train_y.csv\")\n",
    "y_test = pd.read_csv(\"heart_test_y.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66110c3",
   "metadata": {},
   "source": [
    "### 2. Model the data\n",
    "\n",
    "Dataframe will be constructed to contain all the outcomes obtained from our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d09cd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.DataFrame({\"model\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286e7398",
   "metadata": {},
   "source": [
    "### 3. Choosing the right performance metric\n",
    "\n",
    "In this dataset, a false-negative result would indicate that a person with heart disease is wrongly classified as healthy. Therefore, it is crucial to choose a model that minimizes the number of false negatives and thus, maximizes the recall value. Also, the cost of a false-negative result in this model is very high and would result in death of the patient.\n",
    "\n",
    "Hence, recall will be used to measure the performance of the models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b473f3",
   "metadata": {},
   "source": [
    "### 4. Logistic Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fe7a27",
   "metadata": {},
   "source": [
    "#### 4.1 Define parameter distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2798b097",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_lr = {'penalty': ['None','l1', 'l2']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98b41e1",
   "metadata": {},
   "source": [
    "#### 4.2 Performing Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22321d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best recall score is 0.8243968739381582\n",
      "... with parameters: {'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "#Defining scoring metric\n",
    "score_measure = \"recall\"\n",
    "\n",
    "# define the logistic regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Create a random search object\n",
    "random_search_lr = RandomizedSearchCV(estimator=model, param_distributions=param_grid_lr, n_iter=100, cv=5, random_state=42)\n",
    "\n",
    "# Fit the random search to the data\n",
    "_ = random_search_lr.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(f\"The best {score_measure} score is {random_search_lr.best_score_}\")\n",
    "print(f\"... with parameters: {random_search_lr.best_params_}\")\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b69899",
   "metadata": {},
   "source": [
    "#### 4.3 Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "340678be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Best parameters: {'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "#Defining scoring metric\n",
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "#Using best parameters found from random search\n",
    "param_grid_lrg = {'penalty': ['l2']}\n",
    "\n",
    "# define the logistic regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# define the grid search\n",
    "grid_search_lr = GridSearchCV(estimator = model, param_grid=param_grid_lrg, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "# fit the grid search to the data\n",
    "_ = grid_search_lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#Best parameters\n",
    "print(f\"Best parameters: {grid_search_lr.best_params_}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ab6ee2",
   "metadata": {},
   "source": [
    "#### 4.4 Predict with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1f73731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.772532</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.743802</td>\n",
       "      <td>0.772532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  Accuracy  Precision    Recall        F1\n",
       "0  Logistic Regression  0.772532   0.803571  0.743802  0.772532"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search_lr.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Logistic Regression\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d7bb32",
   "metadata": {},
   "source": [
    "### 5. SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6b856c",
   "metadata": {},
   "source": [
    "#### 5.1 Define parameter distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1bb0a2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_SVM = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    " ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f771ee",
   "metadata": {},
   "source": [
    "#### 5.2  Performing Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "abb1bcf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best parameters found: {'kernel': 'rbf', 'gamma': 0.0001, 'C': 1}\n"
     ]
    }
   ],
   "source": [
    "# Create an SVM classifier\n",
    "svm = SVC()\n",
    "\n",
    "# Create a random search object\n",
    "random_search_SVM = RandomizedSearchCV(\n",
    "    svm, \n",
    "    param_distributions=param_grid_SVM, \n",
    "    n_iter=50, # number of parameter combinations to try\n",
    "    cv=5, # number of cross-validation folds\n",
    "    scoring='recall', # scoring metric to use\n",
    "    verbose=1, \n",
    "    n_jobs=-1 # number of CPU cores to use for parallel computation\n",
    ")\n",
    "\n",
    "\n",
    "# Fit the random search to the data\n",
    "_= random_search_SVM.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(\"Best parameters found:\", random_search_SVM.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bd7179",
   "metadata": {},
   "source": [
    "#### 5.3 Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8fd9be0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(), n_jobs=-1,\n",
       "             param_grid=[{'C': [1], 'gamma': [0.0001], 'kernel': ['rbf']}],\n",
       "             scoring='recall', verbose=1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using the best parameters found from random search\n",
    "param_grid_SVMg = [\n",
    "  {'C': [1], \n",
    "   'kernel': ['rbf'],\n",
    "   'gamma': [0.0001]}\n",
    "  \n",
    "]\n",
    "\n",
    "# Create an SVM classifier\n",
    "svm = SVC()\n",
    "\n",
    "# Create a grid search object\n",
    "grid_search_SVM = GridSearchCV(\n",
    "    svm, \n",
    "    param_grid=param_grid_SVMg, \n",
    "    cv=5, # number of cross-validation folds\n",
    "    scoring='recall', # scoring metric to use\n",
    "    verbose=1, \n",
    "    n_jobs=-1 # number of CPU cores to use for parallel computation\n",
    ")\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search_SVM.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ffc87578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.772532</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.743802</td>\n",
       "      <td>0.772532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.519313</td>\n",
       "      <td>0.519313</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.683616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  Accuracy  Precision    Recall        F1\n",
       "0  Logistic Regression  0.772532   0.803571  0.743802  0.772532\n",
       "0                  SVM  0.519313   0.519313  1.000000  0.683616"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search_SVM.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"SVM\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddac3db",
   "metadata": {},
   "source": [
    "### 6. Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7393a3dd",
   "metadata": {},
   "source": [
    "#### 6.1 Define Parameter Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08cd8718",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_dtree = {\n",
    "    'min_samples_split': np.arange(1,200),  \n",
    "    'min_samples_leaf': np.arange(1,200),\n",
    "    'max_leaf_nodes': np.arange(5, 200), \n",
    "    'max_depth': np.arange(1,50), \n",
    "    'criterion': ['entropy', 'gini'],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0283f329",
   "metadata": {},
   "source": [
    "#### 6.2 Perform Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eefc5026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "The best recall score is 0.8442857142857143\n",
      "... with parameters: {'min_samples_split': 193, 'min_samples_leaf': 25, 'max_leaf_nodes': 36, 'max_depth': 14, 'criterion': 'gini'}\n"
     ]
    }
   ],
   "source": [
    "# Define scoring measure\n",
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "# Create a decision tree object\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "# Use RandomizedSearchCV to search over the parameter grid\n",
    "random_search_dtree = RandomizedSearchCV(estimator = dtree, param_distributions=param_grid_dtree, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "# Fit the random search object to the data\n",
    "_ = random_search_dtree.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and score\n",
    "\n",
    "print(f\"The best {score_measure} score is {random_search_dtree.best_score_}\")\n",
    "print(f\"... with parameters: {random_search_dtree.best_params_}\")\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d44b4a",
   "metadata": {},
   "source": [
    "#### 6.3 Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b01442e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 256 candidates, totalling 1280 fits\n",
      "The best recall score is 0.8442857142857143\n",
      "... with parameters: {'criterion': 'gini', 'max_depth': 20, 'max_leaf_nodes': 49, 'min_samples_leaf': 23, 'min_samples_split': 176}\n"
     ]
    }
   ],
   "source": [
    "#Define scoring measure\n",
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "#Using best parameters found from random search\n",
    "param_grid_dtreeg = {\n",
    "    'min_samples_split': np.arange(176,180),  \n",
    "    'min_samples_leaf': np.arange(22,26),\n",
    "    'max_leaf_nodes': np.arange(49,53), \n",
    "    'max_depth': np.arange(20,24), \n",
    "    'criterion': ['gini'],\n",
    "}\n",
    "\n",
    "# Create a decision tree object\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "# Create a grid search object\n",
    "grid_search_dtree = GridSearchCV(estimator = dtree, param_grid=param_grid_dtreeg, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "_ = grid_search_dtree.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Print the best parameters and score\n",
    "print(f\"The best {score_measure} score is {grid_search_dtree.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search_dtree.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a506d43d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.772532</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.743802</td>\n",
       "      <td>0.772532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.519313</td>\n",
       "      <td>0.519313</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.683616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision tree</td>\n",
       "      <td>0.738197</td>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.809917</td>\n",
       "      <td>0.762646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  Accuracy  Precision    Recall        F1\n",
       "0  Logistic Regression  0.772532   0.803571  0.743802  0.772532\n",
       "0                  SVM  0.519313   0.519313  1.000000  0.683616\n",
       "0        Decision tree  0.738197   0.720588  0.809917  0.762646"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search_dtree.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Decision tree\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2422404c",
   "metadata": {},
   "source": [
    "### 7 Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b08d76a",
   "metadata": {},
   "source": [
    "#### 7.1 Define parameter distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1504bcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_nn = {\n",
    "    'hidden_layer_sizes': [ (50,), (70,),(50,30), (40,20), (60,40, 20), (70,50,40)],\n",
    "    'activation': ['logistic', 'tanh', 'relu'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0, .2, .5, .7, 1],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1, 0.2, 0.5],\n",
    "    'max_iter': [5000]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd3e7f5",
   "metadata": {},
   "source": [
    "#### 7.2 Perform Random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "821fa57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "{'solver': 'sgd', 'max_iter': 5000, 'learning_rate_init': 0.5, 'learning_rate': 'adaptive', 'hidden_layer_sizes': (50,), 'alpha': 1, 'activation': 'tanh'}\n"
     ]
    }
   ],
   "source": [
    "#Defining Scoring metric\n",
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "#Create a MLP classifier\n",
    "ann = MLPClassifier()\n",
    "\n",
    "#Use RandomizedSearchCV to search over the parameter grid\n",
    "random_search_nn = RandomizedSearchCV(estimator = ann, param_distributions=param_grid_nn, cv=kfolds, n_iter=100,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "# Fit the random search object to the data\n",
    "_ = random_search_nn.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and score\n",
    "bestRecallTree = random_search_nn.best_estimator_\n",
    "print(random_search_nn.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ff88c4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79       112\n",
      "           1       0.81      0.79      0.80       121\n",
      "\n",
      "    accuracy                           0.80       233\n",
      "   macro avg       0.80      0.80      0.80       233\n",
      "weighted avg       0.80      0.80      0.80       233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c977cc7",
   "metadata": {},
   "source": [
    "#### 7.3 Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "da64f013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "{'activation': 'relu', 'alpha': 1, 'hidden_layer_sizes': (50,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.7, 'max_iter': 5000, 'solver': 'sgd'}\n"
     ]
    }
   ],
   "source": [
    "#Define scoring measure\n",
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "#Using best parameters found from random search\n",
    "param_grid_nng = {\n",
    "    'hidden_layer_sizes': [ (30,), (50,), (70,), (90,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd'],\n",
    "    'alpha': [.5, .7, 1],\n",
    "    'learning_rate': ['adaptive', 'invscaling'],\n",
    "    'learning_rate_init': [0.2, 0.5, 0.7],\n",
    "    'max_iter': [5000]\n",
    "}\n",
    "\n",
    "#Create a MLP classifier\n",
    "ann = MLPClassifier()\n",
    "\n",
    "# Create a grid search object\n",
    "grid_search_nn = GridSearchCV(estimator = ann, param_grid=param_grid_nng, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "_ = grid_search_nn.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and score\n",
    "bestRecallTree = grid_search_nn.best_estimator_\n",
    "\n",
    "print(grid_search_nn.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4231649d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.81      0.78       112\n",
      "           1       0.81      0.75      0.78       121\n",
      "\n",
      "    accuracy                           0.78       233\n",
      "   macro avg       0.78      0.78      0.78       233\n",
      "weighted avg       0.78      0.78      0.78       233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f3fb81e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.772532</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.743802</td>\n",
       "      <td>0.772532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.519313</td>\n",
       "      <td>0.519313</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.683616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision tree</td>\n",
       "      <td>0.738197</td>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.809917</td>\n",
       "      <td>0.762646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.781116</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.752066</td>\n",
       "      <td>0.781116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  Accuracy  Precision    Recall        F1\n",
       "0  Logistic Regression  0.772532   0.803571  0.743802  0.772532\n",
       "0                  SVM  0.519313   0.519313  1.000000  0.683616\n",
       "0        Decision tree  0.738197   0.720588  0.809917  0.762646\n",
       "0       Neural Network  0.781116   0.812500  0.752066  0.781116"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search_nn.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Neural Net\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c58d98",
   "metadata": {},
   "source": [
    "### Discussion of Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f769efe",
   "metadata": {},
   "source": [
    "The aim of this project was to develop a binary classifier that could predict whether an individual has heart disease or not. To achieve this, four different modeling techniques, namely logistic regression, SVM, decision tree and neural net were used. The primary goal was to select the model that minimized false negatives (i.e., a sick person being wrongly classified as healthy), as this had severe consequences. Additionally, high accuracy values were desirable, particularly true positives, given the evenly split data.\n",
    "\n",
    "After comparing the four models, it was determined that the SVM model has the best recall score among all the models, indicating less false negative predictions. \n",
    "\n",
    "But the SVM model had a lower precision and accuracy score than the other models indicating less accurate identification of true positives. \n",
    "\n",
    "The neural net model also has a good recall score of 0.752, accuracy of 0.781, precision of 0.812 and F1 score of 0.781.However, the decision tree model has a good recall score of 0.809917, indicating fewer false negatives. It also has a good accuracy score of 0.738197 in this case high true positive gives indication of a good model.\n",
    "\n",
    "Given the context of the data, model with high recall and accuracy should be selected, as the cost of false negatives is higher than that of false positives and it is also important to determine the true positives accurately(people with heart disease classified as sick). Decision tree would be the best fit model for this data, as it has a good recall score, as well as a good accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd5f191",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
